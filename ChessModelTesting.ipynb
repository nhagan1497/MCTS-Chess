{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d08173-35c1-403c-a2f5-21952c8c1770",
   "metadata": {},
   "source": [
    "In this notebook I'm going to make a neural network that rates the quality and likelihood of a position on a chess board. The goal is to seed a neural network so that it can later be used as a heuristic for a UCT algorithm and learn through self play. Learning from scratch would take too long to converge to anything meaningful so I'll try to start here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58eb61a-86ee-4b9c-a948-de5fbd90419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b79ab-5390-4967-b572-5ab188b7da68",
   "metadata": {},
   "source": [
    "This is a huge file of past games I found on the internet. I think it's exact purpose is to provide lines to a chess engine. I have to parse the games into a format I can work with, for now the reward from the engine will be -1 for loss, 1 for win, and 0 for draw. I'm going to abstract away black/white by making the current player be \"white\" and switch the game result from -1 to 1 based on whether it's a win or loss when we hit the actual model training. Iteration is for when I start training a model so I can track results over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a433d17a-d2e6-4cc2-b20d-a13f36251e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgn_path = r'C:\\Users\\natha\\Documents\\PythonNotebooks\\data\\Chess\\chess_games.pgn'\n",
    "\n",
    "model_num = 5\n",
    "db_path = f'data/Chess/training_data_{model_num}.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f48c13-7f1f-4998-acf6-a07011c765d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_database():\n",
    "    count = 0\n",
    "    dfs = []\n",
    "    \n",
    "    with open(pgn_path, 'r') as pgn_file:\n",
    "        game = chess.pgn.read_game(pgn_file)\n",
    "        while game:\n",
    "            iteration = 0\n",
    "            board = chess.Board()\n",
    "            score = game.headers['Result']\n",
    "            if score == '1/2-1/2':\n",
    "                score = 0\n",
    "            elif score == '1-0':\n",
    "                score = 1\n",
    "            elif score == '0-1':\n",
    "                score = -1\n",
    "            \n",
    "            rows = []\n",
    "            try:\n",
    "                for move in game.mainline_moves():\n",
    "                    board.push(move)\n",
    "                    rows.append((board.fen(), score, iteration))\n",
    "                dfs.append(pd.DataFrame(data=rows, columns=['fen', 'score', 'iteration']))\n",
    "                count += 1\n",
    "        \n",
    "                if count >= 1000:\n",
    "                    pd.concat(dfs).to_sql('training', conn, if_exists='append', index=False)\n",
    "                    count = 0\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            try:\n",
    "                game = chess.pgn.read_game(pgn_file)\n",
    "            except:\n",
    "                game = chess.pgn.read_game(pgn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88679a2-56e1-4381-bf75-a72fc9783a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    symbol_to_channel = {\n",
    "        'r': 0,\n",
    "        'n': 1,\n",
    "        'b': 2,\n",
    "        'k': 3,\n",
    "        'q': 4,\n",
    "        'p': 5,\n",
    "        'R': 6,\n",
    "        'N': 7,\n",
    "        'B': 8,\n",
    "        'K': 9,\n",
    "        'Q': 10,\n",
    "        'P': 11\n",
    "    }\n",
    "    \n",
    "    def __init__(self, db_path, total_rows, offset=0):        \n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        get_rows = \"\"\"SELECT fen, score, likelihood FROM training LIMIT ? OFFSET ?\"\"\"\n",
    "        cursor.execute(get_rows, (total_rows, offset))\n",
    "        self.data = []\n",
    "        rows = cursor.fetchall()\n",
    "        count = 0\n",
    "        for row in rows:\n",
    "            if count % (total_rows // 10) == 0:\n",
    "                print(f'{count}/{total_rows}')\n",
    "            count += 1\n",
    "            self.data.append(self.fen_to_tensor(row[0], row[1], row[2]))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def fen_to_tensor(fen, score, likelihood):\n",
    "        array = np.zeros((12, 64))\n",
    "        board = chess.Board(fen=fen)\n",
    "        piece_map = board.piece_map()\n",
    "        for square_num in piece_map:\n",
    "            piece_type = str(piece_map[square_num])\n",
    "            channel = ChessDataset.symbol_to_channel[piece_type]\n",
    "            array[channel][square_num] = 1\n",
    "        array = array.reshape(12,8,8)\n",
    "        if board.turn == chess.BLACK:\n",
    "            array = np.concatenate((array[6:], array[:6]), axis=0)\n",
    "            array = np.array([np.flipud(sub_array) for sub_array in array])\n",
    "        return torch.tensor(array, dtype=torch.float32), torch.tensor((score, 1.0), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a180eefe-d798-48ff-917e-6e4f00e3a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1024000\n"
     ]
    }
   ],
   "source": [
    "dataset = ChessDataset(db_path=db_path, total_rows=1024000)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "#validation_dataset = ChessDataset(db_path, total_rows=102400, offset=1024000)\n",
    "#val_dataloader = DataLoader(validation_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d124a5-93c0-488a-b21b-a4f123435994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(12, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU activation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        # Flatten the output for the fully connected layers\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        \n",
    "        # Fully connected layers with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        likelihood = torch.sigmoid(self.fc2(x))\n",
    "        quality = torch.tanh(self.fc3(x))\n",
    "        return quality, likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba042589-e3b1-484b-aa41-954b65fcfa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_fens(batch_size):\n",
    "    board = chess.Board()\n",
    "    starting_pieces = list(board.piece_map().values())\n",
    "    numbers = list(range(2, 33))\n",
    "    weights = np.array(list(range(2, 33)))\n",
    "    weights = weights / sum(weights)\n",
    "\n",
    "    fens = []\n",
    "    for i in range(batch_size):\n",
    "        new_piece_map = {}\n",
    "        random.shuffle(starting_pieces)\n",
    "\n",
    "        random_count = np.random.choice(numbers, p=weights)\n",
    "        count = 0\n",
    "        for value in starting_pieces:\n",
    "            new_piece_map[random.choice(chess.SQUARES)] = value\n",
    "            count += 1\n",
    "            if count >= random_count:\n",
    "                break\n",
    "        board.set_piece_map(new_piece_map)\n",
    "        fens.append(board.fen())\n",
    "    return fens\n",
    "def get_random_tensors(batch_size):\n",
    "    fens = generate_random_fens(64)\n",
    "    input_tensors = []\n",
    "    for fen in fens:\n",
    "        input_tensor, _ = ChessDataset.fen_to_tensor(fen, 0, 0)\n",
    "        input_tensors.append(input_tensor)\n",
    "    inputs = torch.stack(input_tensors)\n",
    "    labels = torch.zeros(64)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a6025b-8904-4a73-bde2-a92025f7675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ChessNet()\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 12\n",
    "\n",
    "quality_criterion = nn.MSELoss()  # You can use Mean Squared Error for quality\n",
    "likelihood_criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c165a644-e19f-4325-8159-d363e9fb9168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12]\n",
      "  Test Loss: 0.1792\n",
      "Epoch [2/12]\n",
      "  Test Loss: 0.0292\n",
      "Epoch [3/12]\n",
      "  Test Loss: 0.0233\n",
      "Epoch [4/12]\n",
      "  Test Loss: 0.0153\n",
      "Epoch [5/12]\n",
      "  Test Loss: 0.0109\n",
      "Epoch [6/12]\n",
      "  Test Loss: 0.0180\n",
      "Epoch [7/12]\n",
      "  Test Loss: 0.0163\n",
      "Epoch [8/12]\n",
      "  Test Loss: 0.0141\n",
      "Epoch [9/12]\n",
      "  Test Loss: 0.0087\n",
      "Epoch [10/12]\n",
      "  Test Loss: 0.0073\n",
      "Epoch [11/12]\n",
      "  Test Loss: 0.0116\n",
      "Epoch [12/12]\n",
      "  Test Loss: 0.0060\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(dataloader, 0):\n",
    "        inputs = inputs.squeeze().to(device)\n",
    "        quality_targets = targets.squeeze()[:, 0].to(device)\n",
    "        likelihood_targets = targets.squeeze()[:, 1].to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        quality_output, likelihood_output = model(inputs)\n",
    "    \n",
    "        # Calculate losses\n",
    "        quality_loss = quality_criterion(quality_output.squeeze(), quality_targets)\n",
    "        likelihood_loss = likelihood_criterion(likelihood_output.squeeze(), likelihood_targets)\n",
    "    \n",
    "        # Backpropagation for quality and likelihood on real data\n",
    "        total_loss = quality_loss + likelihood_loss\n",
    "        total_loss.backward()\n",
    "    \n",
    "        # Train likelihood on fake data\n",
    "        fake_inputs, fake_likelihoods = get_random_tensors(inputs.size(0))\n",
    "        fake_inputs = fake_inputs.to(device)\n",
    "        fake_likelihoods = fake_likelihoods.to(device)\n",
    "    \n",
    "        _, fake_likelihood_output = model(fake_inputs)\n",
    "    \n",
    "        # Calculate likelihood loss on fake data\n",
    "        fake_likelihood_loss = likelihood_criterion(fake_likelihood_output.squeeze(), fake_likelihoods)\n",
    "    \n",
    "        # Backpropagate on fake likelihood loss\n",
    "        fake_likelihood_loss.backward()\n",
    "    \n",
    "        # Accumulate running loss\n",
    "        running_loss += (quality_loss.item() + likelihood_loss.item() + fake_likelihood_loss.item())\n",
    "    \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}]\\n  Test Loss: {running_loss / len(dataloader):.4f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "\n",
    "    #validation_loss = 0.0\n",
    "    #running_quality_loss = 0.0\n",
    "    #with torch.no_grad():\n",
    "    #    for inputs_val, targets_val in val_dataloader:\n",
    "    #        inputs_val = inputs_val.squeeze().to(device)\n",
    "    #        quality_targets_val = targets_val.squeeze()[:, 0].to(device)\n",
    "    #        likelihood_targets_val = targets_val.squeeze()[:, 1].to(device)\n",
    "    #        \n",
    "    #        quality_output_val, likelihood_output_val = model(inputs_val)\n",
    "    #        \n",
    "    #        # Calculate validation losses\n",
    "    #        quality_loss_val = quality_criterion(quality_output_val.squeeze(), quality_targets_val)\n",
    "    #        likelihood_loss_val = likelihood_criterion(likelihood_output_val.squeeze(), likelihood_targets_val)\n",
    "    #        \n",
    "    #        validation_loss += (quality_loss_val + likelihood_loss_val).item()\n",
    "    #        running_quality_loss += quality_loss_val.item()\n",
    "            \n",
    "    #print(f'  Validation Loss: {validation_loss / len(val_dataloader):.4f}\\t {running_quality_loss / len(val_dataloader):.4f}\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cba64f9-a7ef-4f94-994a-6c7c9c678182",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'data/Chess/model_{model_num+1}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
